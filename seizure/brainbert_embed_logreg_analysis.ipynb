{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c0c5c-524c-4626-a5b3-5b982ea99433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Path to dir on Linux Computer\n",
    "os.chdir('/home/vineetreddy/Dropbox/CZW_MIT/BrainBERT')  # Change to the BrainBERT directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)  # Add the parent directory to the system path\n",
    "\n",
    "from demo_brainbert_annotated import *  # importing custom functions\n",
    "from create_labels import create_labels #import custom function to create labels for seizure data\n",
    "import models  # Import custom models (user-defined)\n",
    "\n",
    "# Function to load pre-trained model weights and configuration. \n",
    "# Note that ckpt_path is the path to the pretrained weights of BrainBERT.\n",
    "def load_brainbert_model(ckpt_path):\n",
    "    \"\"\"\n",
    "    Loads the BrainBERT model with pre-trained weights.\n",
    "\n",
    "    Args:\n",
    "        ckpt_path (str): Path to the checkpoint file.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: BrainBERT model with loaded weights.\n",
    "    \"\"\"\n",
    "    cfg = OmegaConf.create({\"upstream_ckpt\": ckpt_path})\n",
    "    brainbert_model = build_model(cfg)  # Build the model with the given configuration\n",
    "    brainbert_model.to('cuda')  # Move the model to GPU\n",
    "    init_state = torch.load(ckpt_path)  # Load the initial state of the model\n",
    "    load_model_weights(brainbert_model, init_state['model'], False)  # Load the model weights\n",
    "    return brainbert_model\n",
    "\n",
    "# Function to generate BrainBERT embeddings from example waveforms\n",
    "def generate_brainbert_embeddings(model, example_wavs):\n",
    "    \"\"\"\n",
    "    Generates BrainBERT embeddings for each example.\n",
    "\n",
    "    Args:\n",
    "        brainbert_model (torch.nn.Module): BrainBERT model.\n",
    "        example_wavs (np.array): Array of example waveforms.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array of BrainBERT embeddings.\n",
    "    \"\"\"\n",
    "    brainbert_outs = []\n",
    "    for example_wav in example_wavs:\n",
    "        # Get the Short-Time Fourier Transform (STFT) of the signal\n",
    "        f, t, linear = get_stft(example_wav, 2048, clip_fs=25, nperseg=400, noverlap=350, normalizing=\"zscore\", return_onesided=True)  # TODO hardcode sampling rate\n",
    "        inputs = torch.FloatTensor(linear).unsqueeze(0).transpose(1, 2).to('cuda')  # Prepare inputs for the model\n",
    "        mask = torch.zeros((inputs.shape[:2])).bool().to('cuda')  # Create a mask for the inputs\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(inputs, mask, intermediate_rep=True)  # Get the model output\n",
    "        brainbert_outs.append(out.cpu().numpy())  # Append the output to the list\n",
    "\n",
    "    # Average over the time dimension to get a single vector per example (example = 5 second window of time series data)\n",
    "    brainbert_outs_arr = np.concatenate(brainbert_outs, axis=0)\n",
    "    brainbert_outs_arr = brainbert_outs_arr.mean(axis=1)\n",
    "    \n",
    "    return brainbert_outs_arr\n",
    "\n",
    "# Load Pre-Trained Model Weights and Configuration\n",
    "ckpt_path = \"/home/vineetreddy/Dropbox/CZW_MIT/stft_large_pretrained_256hz.pth\"  # path to pre-trained weights for model\n",
    "brainbert_model = load_brainbert_model(ckpt_path)  # Load the model\n",
    "\n",
    "# Paths to save/load embeddings and labels\n",
    "embeddings_save_path = \"/home/vineetreddy/brainbert_embeddings.npy\"\n",
    "labels_save_path = \"/home/vineetreddy/brainbert_labels.npy\"\n",
    "\n",
    "# Check if embeddings and labels already exist\n",
    "if os.path.exists(embeddings_save_path) and os.path.exists(labels_save_path):\n",
    "    all_brainbert_outs = np.load(embeddings_save_path)\n",
    "    all_labels = np.load(labels_save_path)\n",
    "    print(\"Loaded embeddings and labels from saved files.\")\n",
    "else:\n",
    "    # Process each file in the directory\n",
    "    directory = '/home/vineetreddy/edf numpy out/'\n",
    "    events_dir = '/home/vineetreddy/edf events'  # Directory containing the events .tsv files\n",
    "    all_brainbert_outs = []\n",
    "    all_labels = []\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            \n",
    "            # Load in channel array. Each channel array is organized such that each row is a 5-second window \n",
    "            # and the columns are the time series data\n",
    "            example_wavs = np.load(file_path)\n",
    "\n",
    "            # Generate labels\n",
    "            labels = create_labels(file_path, events_dir)\n",
    "            if labels.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Generate BrainBERT embeddings for each example\n",
    "            brainbert_outs_arr = generate_brainbert_embeddings(brainbert_model, example_wavs)\n",
    "            all_brainbert_outs.append(brainbert_outs_arr)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # Combine all the data\n",
    "    all_brainbert_outs = np.concatenate(all_brainbert_outs, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Save the embeddings and labels\n",
    "    np.save(embeddings_save_path, all_brainbert_outs)\n",
    "    np.save(labels_save_path, all_labels)\n",
    "    print(\"Saved embeddings and labels to files.\")\n",
    "\n",
    "# Logistic Regression\n",
    "model_save_path = \"/home/vineetreddy/save model/logistic_model.joblib\"\n",
    "\n",
    "# Initialize variables\n",
    "brainbert_outs_arr_train = brainbert_outs_arr_test = labels_train = labels_test = None\n",
    "\n",
    "try:\n",
    "    logistic_model = joblib.load(model_save_path)\n",
    "    print(f\"Loaded existing model from {model_save_path}\")\n",
    "    \n",
    "    # If model is loaded, we need to split the data for evaluation\n",
    "    brainbert_outs_arr_train, brainbert_outs_arr_test, labels_train, labels_test = train_test_split(\n",
    "        all_brainbert_outs, all_labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model not found at {model_save_path}, training a new model.\")\n",
    "    \n",
    "    # Split the data using train_test_split\n",
    "    brainbert_outs_arr_train, brainbert_outs_arr_test, labels_train, labels_test = train_test_split(\n",
    "        all_brainbert_outs, all_labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    logistic_model = LogisticRegression()\n",
    "    logistic_model.fit(brainbert_outs_arr_train, labels_train)  # Fit the logistic regression model\n",
    "\n",
    "    # Save the logistic regression model\n",
    "    joblib.dump(logistic_model, model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # Predict the labels for the training set\n",
    "    predictions_train = logistic_model.predict(brainbert_outs_arr_train)\n",
    "    acc_train = np.mean(predictions_train == labels_train)\n",
    "    print(f'Training Accuracy: {acc_train}')\n",
    "\n",
    "# Predict the labels for the test set\n",
    "predictions = logistic_model.predict(brainbert_outs_arr_test)  # Predict the labels\n",
    "acc = np.mean(predictions == labels_test)\n",
    "print(f\"Test Accuracy: {acc}\")\n",
    "\n",
    "# Save predictions and true labels for ROC/AUC plot\n",
    "np.save(\"/home/vineetreddy/roc_logreg/predictions.npy\", predictions)\n",
    "np.save(\"/home/vineetreddy/roc_logreg/labels_test.npy\", labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e8981-52a8-48e3-ac5f-d3d14b1550c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Assuming all required functions and model loading are defined in the notebook\n",
    "\n",
    "# Load embeddings and labels\n",
    "embeddings_save_path = \"/home/vineetreddy/brainbert_embeddings.npy\"\n",
    "labels_save_path = \"/home/vineetreddy/brainbert_labels.npy\"\n",
    "\n",
    "all_brainbert_outs = np.load(embeddings_save_path)\n",
    "all_labels = np.load(labels_save_path)\n",
    "\n",
    "# PCA of BrainBERT Embeddings\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(all_brainbert_outs)\n",
    "\n",
    "# Print the variance explained by the first two components\n",
    "variance_explained = pca.explained_variance_ratio_\n",
    "print(f\"Variance explained by the first component: {variance_explained[0]:.2f}\")\n",
    "print(f\"Variance explained by the second component: {variance_explained[1]:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=all_labels, cmap='viridis', s=5)\n",
    "plt.title('PCA of BrainBERT Embeddings')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Label')\n",
    "plt.show()\n",
    "\n",
    "# Logistic Regression Model Loading and Evaluation\n",
    "model_save_path = \"/home/vineetreddy/save model/logistic_model.joblib\"\n",
    "logistic_model = joblib.load(model_save_path)\n",
    "\n",
    "# Split the data for evaluation\n",
    "brainbert_outs_arr_train, brainbert_outs_arr_test, labels_train, labels_test = train_test_split(\n",
    "    all_brainbert_outs, all_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Training and Test Accuracy\n",
    "train_accuracy = np.mean(logistic_model.predict(brainbert_outs_arr_train) == labels_train)\n",
    "test_accuracy = np.mean(logistic_model.predict(brainbert_outs_arr_test) == labels_test)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(['Training Accuracy', 'Test Accuracy'], [train_accuracy, test_accuracy], color=['blue', 'green'])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance')\n",
    "\n",
    "# Annotate bars with accuracy values\n",
    "for bar, accuracy in zip(bars, [train_accuracy, test_accuracy]):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, f'{accuracy:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "predictions = logistic_model.predict(brainbert_outs_arr_test)\n",
    "conf_matrix = confusion_matrix(labels_test, predictions)\n",
    "\n",
    "# Specify the labels explicitly\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Non-Seizure', 'Seizure'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(labels_test, logistic_model.predict_proba(brainbert_outs_arr_test)[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1b857-a593-450f-9c50-0024d6c8593e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
