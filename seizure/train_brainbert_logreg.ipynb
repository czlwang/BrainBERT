{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b2c84b-2044-41c9-b75e-9d1f0ff1911b",
   "metadata": {},
   "source": [
    "# BrainBERT Seizure Detection with Logistic Regression Pipeline\n",
    "\n",
    "This script is designed to import necessary libraries and modules, set up the working environment, load a pre-trained BrainBERT model, process EEG data to generate embeddings, and train a logistic regression model for seizure detection. \n",
    "\n",
    "1. **Import Libraries and Modules**: The script begins by importing essential libraries and modules, such as `numpy` for numerical operations, `matplotlib` for plotting, `scipy` for signal processing, `torch` for deep learning, `omegaconf` for configuration management, and `sklearn` for machine learning tasks.\n",
    "\n",
    "2. **Set Working Directory**: The working directory is set to the BrainBERT directory, and the parent directory is added to the system path to ensure all custom modules can be imported.\n",
    "\n",
    "3. **Import Custom Functions and Models**: Custom functions and models specific to the BrainBERT project are imported. These include functions for creating labels and handling the BrainBERT model.\n",
    "\n",
    "4. **Load Pre-Trained Model**: A function `load_brainbert_model` is defined to load the BrainBERT model with pre-trained weights. It uses a configuration file and checkpoint path to build and initialize the model on a GPU.\n",
    "\n",
    "5. **Generate BrainBERT Embeddings**: A function `generate_brainbert_embeddings` is defined to process example waveforms and generate BrainBERT embeddings. This involves calculating the Short-Time Fourier Transform (STFT) of the signal, preparing inputs for the model, and obtaining model outputs.\n",
    "\n",
    "6. TODO! Change (**Load Pre-Trained Weights**: The script loads pre-trained weights for the BrainBERT model from a specified checkpoint path.\n",
    "\n",
    "7. **Process EEG Data**: The script iterates over `.npy` files in a specified directory, loading the waveforms and generating corresponding labels. It then generates BrainBERT embeddings for each example and stores the results.\n",
    "\n",
    "8. **Combine Data**: All generated BrainBERT embeddings and labels are concatenated into single arrays.\n",
    "\n",
    "9. **Train-Test Split**: The data is split into training and testing sets using an 80-20 split to ensure reproducibility.\n",
    "\n",
    "10. **Train Logistic Regression Model**: A logistic regression model is trained using the training data. The trained model is then saved to a specified path.\n",
    "\n",
    "11. **Evaluate Model**: The logistic regression model predicts labels for the test set, and the accuracy of the predictions is calculated and printed.\n",
    "\n",
    "This script provides a comprehensive workflow for processing EEG data, generating embeddings using a pre-trained BrainBERT model, and training a machine learning model for seizure detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c0c5c-524c-4626-a5b3-5b982ea99433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries and Modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Set the working directory to the BrainBERT directory\n",
    "os.chdir('/home/vineetreddy/Dropbox/CZW_MIT/BrainBERT')\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)  # Add the parent directory to the system path\n",
    "\n",
    "# Import custom functions and models\n",
    "from demo_brainbert_annotated import *  # Importing custom functions\n",
    "from create_labels import create_labels  # Import custom function to create labels for seizure data\n",
    "import models  # Import custom models (user-defined)\n",
    "\n",
    "# Function to load pre-trained model weights and configuration\n",
    "def load_brainbert_model(ckpt_path):\n",
    "    \"\"\"\n",
    "    Loads the BrainBERT model with pre-trained weights.\n",
    "\n",
    "    Args:\n",
    "        ckpt_path (str): Path to the checkpoint file.\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: BrainBERT model with loaded weights.\n",
    "    \"\"\"\n",
    "    cfg = OmegaConf.create({\"upstream_ckpt\": ckpt_path})\n",
    "    brainbert_model = build_model(cfg)  # Build the model with the given configuration\n",
    "    brainbert_model.to('cuda')  # Move the model to GPU\n",
    "    init_state = torch.load(ckpt_path)  # Load the initial state of the model\n",
    "    load_model_weights(brainbert_model, init_state['model'], False)  # Load the model weights\n",
    "    return brainbert_model\n",
    "\n",
    "# Function to generate BrainBERT embeddings from example waveforms\n",
    "def generate_brainbert_embeddings(model, example_wavs):\n",
    "    \"\"\"\n",
    "    Generates BrainBERT embeddings for each example.\n",
    "\n",
    "    Args:\n",
    "        brainbert_model (torch.nn.Module): BrainBERT model.\n",
    "        example_wavs (np.array): Array of example waveforms.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Array of BrainBERT embeddings.\n",
    "    \"\"\"\n",
    "    brainbert_outs = []\n",
    "    for example_wav in example_wavs:\n",
    "        # Get the Short-Time Fourier Transform (STFT) of the signal\n",
    "        f, t, linear = get_stft(example_wav, 2048, clip_fs=25, nperseg=400, noverlap=350, normalizing=\"zscore\", return_onesided=True)\n",
    "        inputs = torch.FloatTensor(linear).unsqueeze(0).transpose(1, 2).to('cuda')  # Prepare inputs for the model\n",
    "        mask = torch.zeros((inputs.shape[:2])).bool().to('cuda')  # Create a mask for the inputs\n",
    "        with torch.no_grad():\n",
    "            out = brainbert_model.forward(inputs, mask, intermediate_rep=True)  # Get the model output\n",
    "        brainbert_outs.append(out.cpu().numpy())  # Append the output to the list\n",
    "\n",
    "    # Concatenate and average the outputs\n",
    "    brainbert_outs_arrr = np.concatenate(brainbert_outs, axis=0)\n",
    "    brainbert_outs_arr = brainbert_outs_arrr.mean(axis=1)\n",
    "    \n",
    "    return brainbert_outs_arr\n",
    "\n",
    "# Load Pre-Trained Model Weights and Configuration\n",
    "ckpt_path = \"/home/vineetreddy/Dropbox/CZW_MIT/stft_large_pretrained_256hz.pth\"  # Path to pre-trained weights for the model\n",
    "brainbert_model = load_brainbert_model(ckpt_path)  # Load the model\n",
    "\n",
    "# Directory paths\n",
    "directory = '/home/vineetreddy/edf numpy out/'  # Directory containing .npy files\n",
    "events_dir = '/home/vineetreddy/edf events'  # Directory containing the events .tsv files\n",
    "all_brainbert_outs = []\n",
    "all_labels = []\n",
    "\n",
    "# Process each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".npy\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Load in channel array. Each channel array is organized such that each row is a 5-second window \n",
    "        # and the columns are the time series data\n",
    "        example_wavs = np.load(file_path)\n",
    "\n",
    "        # Generate labels\n",
    "        labels = create_labels(file_path, events_dir)\n",
    "        if labels.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Generate BrainBERT embeddings for each example\n",
    "        brainbert_outs_arr = generate_brainbert_embeddings(brainbert_model, example_wavs)\n",
    "        all_brainbert_outs.append(brainbert_outs_arr)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "# Combine all the data\n",
    "all_brainbert_outs = np.concatenate(all_brainbert_outs, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# 80% of the data for training and 20% for testing; random_state=42 ensures reproducibility of the split\n",
    "brainbert_outs_arr_train, brainbert_outs_arr_test, labels_train, labels_test = train_test_split(\n",
    "    all_brainbert_outs, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(brainbert_outs_arr_train, labels_train)  # Fit the logistic regression model\n",
    "\n",
    "# Save the logistic regression model\n",
    "model_save_path = \"/home/vineetreddy/save model/logistic_model.joblib\"\n",
    "joblib.dump(logistic_model, model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "# Predict the labels\n",
    "predictions = logistic_model.predict(brainbert_outs_arr_test)  # Predict the labels\n",
    "acc = np.mean(predictions == labels_test)\n",
    "print(f\"Accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb8d62-b8b2-45e4-a345-bcce0ca42cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
